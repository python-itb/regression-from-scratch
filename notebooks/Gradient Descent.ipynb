{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In closed loop solution, we set the derivative of RSS w.r.t to each variable to zero. In a more technical term, the matrix of these derivatives is called as Jacobian matrix $\\vec J$. However, most function couldn't be treated this way. They are just so complicated that it is virtually impossible to find the global minimum / maximum by setting it to zero. So, we're going to use a very powerful algorithm called Gradient Descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of closed form solution and gradient descent is still the same, which is to find the set of parameters, in this case $b_0$ and $b_1$ which would minimize the RSS. But instead of directly finding it by setting the derivation of RSS to zero, we're going to iteratively change $b_0$ and $b_1$ so that eventually we would find the global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us formally define $\\vec J$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\vec J = \n",
    "\\begin{pmatrix}\n",
    "    \\frac{\\partial C}{\\partial b_0}\\\\\n",
    "    \\frac{\\partial C}{\\partial b_1}\\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Now the question, how could we attain this?\n",
    "\n",
    "Let's go back to the image of RSS vs $b_0$ and $b_1$. \n",
    "\n",
    "<img src=\"./images/RSS_vs_param.png\" width=40%>\n",
    "\n",
    "However, that plot is too convoluted for our purpose. Suppose that we only have one parameter $w$ that would decide the value of our cost function $C$. Then the plot would be\n",
    "\n",
    "<img src=\"./images/gd.png\" width=40%>\n",
    "\n",
    "The y-axis and x-axis denotes the RSS value and $w$ respectively. If you notice that the global minimum is located exactly in the middle. Our goal is to estimate that $w$ so that RSS is globally minimized.\n",
    "\n",
    "The idea of gradient descent is that, instead of directly finding the $w$, we're going to iteratively change the amount of $w$ until RSS is minimized. We would step down the hill until we reach the lowest point. Now the question would be, how do we know the direction so we would arrive at the global minimum?\n",
    "\n",
    "The answer lies in the plot. Notice that if we are standing in the left side of the minimum, when the gradient is negative, then we should increase the $w$. On the other hand, suppose that we're located on the right side, when the gradient is positive, then we should go back, or in other words, decrease the $w$.\n",
    "\n",
    "This idea is expressed beautifully in gradient descent algorithm\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    " w^{t+1} &=& w^t-\\alpha \\vec J\\nonumber\\\\\n",
    "   &=& w^t-\\alpha \\frac{\\partial C}{\\partial w}\\nonumber\\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "As in our case\n",
    "\\begin{eqnarray}\n",
    " w^{t+1} &=& w^t-\\alpha \\frac{\\partial C}{\\partial w}\\nonumber\\\\\n",
    "      &=& w^t-\\alpha \\begin{pmatrix}\n",
    "        \\frac{\\partial C}{\\partial b_0}\\\\\n",
    "        \\frac{\\partial C}{\\partial b_1}\\\\\n",
    "    \\end{pmatrix}\\\\\n",
    "    &=& w^t-\\alpha \\begin{pmatrix}\n",
    "        -2 \\sum(y-(b_0+b_1x))\\nonumber\\\\\\\\\n",
    "        -2 \\sum(y-b_0-b_1x)(x)\\nonumber\\\\\n",
    "    \\end{pmatrix}\n",
    "\\end{eqnarray}\n",
    "\n",
    "$\\alpha$ denotes the timesteps or how big our leap each time we move. Later on we would show that if we set $\\alpha$ too big, then we won't find the global minimum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
